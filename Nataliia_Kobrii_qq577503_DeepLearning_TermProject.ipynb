{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af859067",
   "metadata": {},
   "source": [
    "\n",
    "# AI - Based Reading Assistant for Children Using Wav2Vec2\n",
    "## Student: Nataliia Kobrii. \n",
    "## UTORid: qq577503\n",
    "This project builds a prototype **“Reading Assistant”** that helps children practice reading aloud. \n",
    "I use a pretrained **deep learning model (Wav2Vec2-Base-960h)** to transcribe the child’s speech, \n",
    "compare it to **the expected sentence using Word Error Rate (WER)**, and detect which words were \n",
    "spoken incorrectly. Finally, I provide phonics-based feedback to help the child improve reading \n",
    "and pronunciation. **The goal is to evaluate how well an adult-trained ASR model performs on \n",
    "children’s speech and to design a feedback mechanism that supports learning.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2fb82f-aba1-4d7f-a576-3bff744c8b26",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Imports & Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a8eb92-2be4-4f56-8f69-720a098f8911",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset\n",
    "\n",
    "The dataset consists of 10 short English sentences designed for early readers. \n",
    "Each sentence was recorded once by a Grade 1 child reader who is still developing \n",
    "English reading and pronunciation skills at home. For privacy reasons, the audio files are not included in this submission, \n",
    "but the notebook contains full logs of the model predictions for each sentence. \n",
    "The model never stores or learns from audio, and recordings are only used locally \n",
    "for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d34a216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/natalikobrii/miniconda3/envs/kidread/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s01</td>\n",
       "      <td>The cat is sleeping.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s02</td>\n",
       "      <td>The dog is very happy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s03</td>\n",
       "      <td>The sun is shining.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s04</td>\n",
       "      <td>She has a red ball.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s05</td>\n",
       "      <td>The bird is on the tree.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                      text\n",
       "0  s01      The cat is sleeping.\n",
       "1  s02    The dog is very happy.\n",
       "2  s03       The sun is shining.\n",
       "3  s04       She has a red ball.\n",
       "4  s05  The bird is on the tree."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from jiwer import wer\n",
    "from difflib import SequenceMatcher\n",
    "import matplotlib.pyplot as plt\n",
    "import pyttsx3\n",
    "\n",
    "# Project paths\n",
    "DATA_DIR = \"../data\"\n",
    "CHILD_DIR = os.path.join(DATA_DIR, \"child_recordings\")\n",
    "SENTENCES_CSV = os.path.join(DATA_DIR, \"sentences.csv\")\n",
    "\n",
    "# Audio settings\n",
    "SAMPLE_RATE = 16000\n",
    "MODEL_NAME = \"facebook/wav2vec2-base-960h\"\n",
    "\n",
    "# Load sentence prompts\n",
    "sentences_df = pd.read_csv(SENTENCES_CSV)\n",
    "sentences_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e309f969-44df-4c65-88da-ad392781be58",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Load Wav2Vec2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b63559aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and processor loaded.\n"
     ]
    }
   ],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(MODEL_NAME)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(MODEL_NAME)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model and processor loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f292be2-528b-4a5c-8ecd-64ee7044e21b",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Audio Loading & ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cec8da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(path, sr=SAMPLE_RATE):\n",
    "    \"\"\"Load an audio file and resample to the target sampling rate.\"\"\"\n",
    "    audio, sr = librosa.load(path, sr=sr)\n",
    "    return audio, sr\n",
    "\n",
    "\n",
    "def transcribe(path):\n",
    "    \"\"\"Transcribe an audio file to text using Wav2Vec2.\"\"\"\n",
    "    audio, sr = load_audio(path)\n",
    "    inputs = processor(audio, sampling_rate=sr, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    text = processor.batch_decode(pred_ids)[0]\n",
    "    return text.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39df0c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASR: that ket is slip\n"
     ]
    }
   ],
   "source": [
    "# Test transcription on the first sentence\n",
    "test_path = os.path.join(CHILD_DIR, \"s01_child.wav\")\n",
    "if os.path.exists(test_path):\n",
    "    print(\"ASR:\", transcribe(test_path))\n",
    "else:\n",
    "    print(\"Record s01_child.wav in data/child_recordings first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46edfebf-1115-4de0-8db9-9795482d5a9c",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Text Normalization & Pronunciation Score (WER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6ea0898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(t):\n",
    "    \"\"\"Lowercase and remove simple punctuation.\"\"\"\n",
    "    t = t.lower().strip()\n",
    "    for ch in [\",\", \".\", \"?\", \"!\", \";\", \":\", \"'\", \"\\\"\"]:\n",
    "        t = t.replace(ch, \"\")\n",
    "    return t\n",
    "\n",
    "\n",
    "def pronunciation_score(target_text, audio_path):\n",
    "    \"\"\"\n",
    "    Compute WER-based pronunciation score between the target sentence\n",
    "    and the child's spoken audio.\n",
    "    \"\"\"\n",
    "    target_norm = normalize_text(target_text)\n",
    "    predicted_text = transcribe(audio_path)\n",
    "    pred_norm = normalize_text(predicted_text)\n",
    "\n",
    "    # 0 = perfect, 1 = completely wrong\n",
    "    error = wer(target_norm, pred_norm)\n",
    "\n",
    "    # convert to 0 - 1; higher = better\n",
    "    score = max(0.0, 1.0 - error)\n",
    "\n",
    "    return {\n",
    "        \"target\": target_text,\n",
    "        \"predicted\": predicted_text,\n",
    "        \"wer\": error,\n",
    "        \"score\": score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b424eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = sentences_df.iloc[0]\n",
    "sid, text = row[\"id\"], row[\"text\"]\n",
    "child_path = os.path.join(CHILD_DIR, f\"{sid}_child.wav\")\n",
    "\n",
    "if os.path.exists(child_path):\n",
    "    result = pronunciation_score(text, child_path)\n",
    "    result\n",
    "else:\n",
    "    print(f\"Missing file: {child_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed95461-f2be-491c-ade9-ed57282d4a5b",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Word-Level Alignment (Correct vs Wrong Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e5c6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_diff(target_text, predicted_text):\n",
    "    \"\"\"\n",
    "    Align words between target and predicted sentences.\n",
    "    Returns a list of (target_word, status, child_word):\n",
    "      - status: \"correct\", \"wrong\", \"missing\"\n",
    "    \"\"\"\n",
    "    t_words = normalize_text(target_text).split()\n",
    "    p_words = normalize_text(predicted_text).split()\n",
    "\n",
    "    matcher = SequenceMatcher(None, t_words, p_words)\n",
    "    aligned = []\n",
    "\n",
    "    for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
    "        if tag == \"equal\":\n",
    "            for i in range(i1, i2):\n",
    "                aligned.append((t_words[i], \"correct\", t_words[i]))\n",
    "\n",
    "        elif tag == \"replace\":\n",
    "            for i in range(i1, i2):\n",
    "                child_word = p_words[j1] if j1 < len(p_words) else None\n",
    "                aligned.append((t_words[i], \"wrong\", child_word))\n",
    "\n",
    "        elif tag == \"delete\":\n",
    "            for i in range(i1, i2):\n",
    "                aligned.append((t_words[i], \"missing\", None))\n",
    "\n",
    "    return aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c6fb2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test word_diff using the previous pronunciation_score result\n",
    "if 'result' in globals():\n",
    "    diff_example = word_diff(result[\"target\"], result[\"predicted\"])\n",
    "    diff_example\n",
    "else:\n",
    "    print(\"Run the pronunciation_score test cell first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304515de-1d00-4273-a90a-ee1e603489a9",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Phonics Rule Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68253e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "RULES = {\n",
    "    \"th_initial\": {\n",
    "        \"title\": \"The 'th' sound\",\n",
    "        \"explain\": (\n",
    "            \"The letters T and H together make the sound 'th'. \"\n",
    "            \"Put your tongue gently between your teeth and blow air: th.\"\n",
    "        ),\n",
    "        \"examples\": \"the, this, that\"\n",
    "    },\n",
    "    \"magic_e\": {\n",
    "        \"title\": \"The magic 'e'\",\n",
    "        \"explain\": (\n",
    "            \"When a word ends with a silent 'e', the vowel often says its name. \"\n",
    "            \"For example, 'cap' becomes 'cape'.\"\n",
    "        ),\n",
    "        \"examples\": \"make, ride, bike\"\n",
    "    },\n",
    "    \"long_ee\": {\n",
    "        \"title\": \"The long 'ee' sound\",\n",
    "        \"explain\": (\n",
    "            \"The letters E E together make a long E sound: 'ee', \"\n",
    "            \"like in 'sleep', 'feet', 'keep'.\"\n",
    "        ),\n",
    "        \"examples\": \"sleep, feet, keep\"\n",
    "    },\n",
    "    \"short_a\": {\n",
    "        \"title\": \"The short 'a' sound\",\n",
    "        \"explain\": (\n",
    "            \"Short 'a' is a quick sound: 'a', like in 'cat', 'hat', 'bat'.\"\n",
    "        ),\n",
    "        \"examples\": \"cat, hat, bat\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e84544f-7f3c-48a6-907f-f5ae8b45b6cb",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Rule Matching & Text Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6352e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_rule_for_word(word):\n",
    "    \"\"\"Return a RULES entry for the given word.\"\"\"\n",
    "    w = word.lower()\n",
    "\n",
    "    if w.startswith(\"th\"):\n",
    "        return RULES[\"th_initial\"]\n",
    "    if \"ee\" in w:\n",
    "        return RULES[\"long_ee\"]\n",
    "    if len(w) >= 3 and w.endswith(\"e\") and w[-2] in \"aeiou\":\n",
    "        return RULES[\"magic_e\"]\n",
    "    if len(w) == 3 and w[1] == \"a\" and w[-1] in \"ptdn\":\n",
    "        return RULES[\"short_a\"]\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def feedback_for_word(target_word, child_word=None):\n",
    "    \"\"\"Generate a child-friendly explanation for target_word.\"\"\"\n",
    "    rule = find_rule_for_word(target_word)\n",
    "\n",
    "    if rule is None:\n",
    "        if child_word:\n",
    "            return (\n",
    "                f\"We say '{target_word}', not '{child_word}'. \"\n",
    "                f\"Let's repeat '{target_word}' together.\"\n",
    "            )\n",
    "        else:\n",
    "            return (\n",
    "                f\"Let's try the word '{target_word}' again. \"\n",
    "                f\"Read it slowly and clearly.\"\n",
    "            )\n",
    "\n",
    "    return (\n",
    "        f\"We say '{target_word}'. \"\n",
    "        f\"{rule['title']}. {rule['explain']} \"\n",
    "        f\"For example: {rule['examples']}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710b9de0-94af-4eca-bd50-00ba71da9074",
   "metadata": {},
   "source": [
    "\n",
    "## 9. Text-to-Speech (TTS) for Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d391b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize text-to-speech engine\n",
    "tts = pyttsx3.init()\n",
    "\n",
    "def speak(text):\n",
    "    try:\n",
    "        import pyttsx3\n",
    "        engine = pyttsx3.init()\n",
    "        engine.say(text)\n",
    "        engine.runAndWait()\n",
    "    except:\n",
    "        print(\"[AUDIO] \" + text)\n",
    "\n",
    "def explain_rule_with_audio(target_word, child_word=None):\n",
    "    \"\"\"Print and speak a phonics explanation for the target word.\"\"\"\n",
    "    msg = feedback_for_word(target_word, child_word)\n",
    "    print(\"Audio explanation:\", msg)\n",
    "    speak(msg)\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82332232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio explanation: We say 'sleeping'. The long 'ee' sound. The letters E E together make a long E sound: 'ee', like in 'sleep', 'feet', 'keep'. For example: sleep, feet, keep.\n"
     ]
    }
   ],
   "source": [
    "# Test TTS explanation\n",
    "_ = explain_rule_with_audio(\"sleeping\", \"sliping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c60e66-be4e-49ed-97ce-e5ea37ab3419",
   "metadata": {},
   "source": [
    "\n",
    "## 10. End-to-End Evaluation for One Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45c344fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sentence(row, child_suffix=\"child\"):\n",
    "    \"\"\"\n",
    "    Evaluate one sentence for the child recording sXX_child.wav.\n",
    "    \"\"\"\n",
    "    sid, text = row[\"id\"], row[\"text\"]\n",
    "    child_path = os.path.join(CHILD_DIR, f\"{sid}_{child_suffix}.wav\")\n",
    "\n",
    "    if not os.path.exists(child_path):\n",
    "        print(f\"Missing audio file: {child_path}\")\n",
    "        return None\n",
    "\n",
    "    # 1. Overall pronunciation score\n",
    "    pron = pronunciation_score(text, child_path)\n",
    "    diff = word_diff(pron[\"target\"], pron[\"predicted\"])\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Sentence {sid}\")\n",
    "    print(f\"Target:    {pron['target']}\")\n",
    "    print(f\"Predicted: {pron['predicted']}\")\n",
    "    print(f\"WER: {pron['wer']:.2f} -> Score: {pron['score']:.2f}\")\n",
    "\n",
    "    print(\"\\nWord-level feedback:\")\n",
    "    for w, status, child_w in diff:\n",
    "        mark = \"Correct:\" if status == \"correct\" else \"Needs correction:\"\n",
    "        print(f\"{mark}  {w}   (heard: {child_w})\")\n",
    "\n",
    "    print(\"\\nAudio help for tricky words:\")\n",
    "    for w, status, child_w in diff:\n",
    "        if status != \"correct\":\n",
    "            explain_rule_with_audio(w, child_w)\n",
    "\n",
    "    # Overall summary\n",
    "    score = pron[\"score\"]\n",
    "    if score >= 0.8:\n",
    "        print(\"\\nOverall: Excellent! Great reading.\")\n",
    "    elif score >= 0.6:\n",
    "        print(\"\\nOverall: Good, but some words need practice.\")\n",
    "    else:\n",
    "        print(\"\\nOverall: Needs practice with this sentence.\")\n",
    "\n",
    "    return {**pron, \"id\": sid, \"diff\": diff}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "992fca6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Sentence s01\n",
      "Target:    The cat is sleeping.\n",
      "Predicted: that ket is slip\n",
      "WER: 0.75 -> Score: 0.25\n",
      "\n",
      "Word-level feedback:\n",
      "Needs correction:  the   (heard: that)\n",
      "Needs correction:  cat   (heard: that)\n",
      "Correct:  is   (heard: is)\n",
      "Needs correction:  sleeping   (heard: slip)\n",
      "\n",
      "Audio help for tricky words:\n",
      "Audio explanation: We say 'the'. The 'th' sound. The letters T and H together make the sound 'th'. Put your tongue gently between your teeth and blow air: th. For example: the, this, that.\n",
      "Audio explanation: We say 'cat'. The short 'a' sound. Short 'a' is a quick sound: 'a', like in 'cat', 'hat', 'bat'. For example: cat, hat, bat.\n",
      "Audio explanation: We say 'sleeping'. The long 'ee' sound. The letters E E together make a long E sound: 'ee', like in 'sleep', 'feet', 'keep'. For example: sleep, feet, keep.\n",
      "\n",
      "Overall: Needs practice with this sentence.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'target': 'The cat is sleeping.',\n",
       " 'predicted': 'that ket is slip',\n",
       " 'wer': 0.75,\n",
       " 'score': 0.25,\n",
       " 'id': 's01',\n",
       " 'diff': [('the', 'wrong', 'that'),\n",
       "  ('cat', 'wrong', 'that'),\n",
       "  ('is', 'correct', 'is'),\n",
       "  ('sleeping', 'wrong', 'slip')]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the first sentence\n",
    "evaluate_sentence(sentences_df.iloc[0], child_suffix=\"child\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8beb0f-ee18-4ae2-9245-76ea7b406489",
   "metadata": {},
   "source": [
    "\n",
    "## 11. Evaluate All Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "898438ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Sentence s01\n",
      "Target:    The cat is sleeping.\n",
      "Predicted: that ket is slip\n",
      "WER: 0.75 -> Score: 0.25\n",
      "\n",
      "Word-level feedback:\n",
      "Needs correction:  the   (heard: that)\n",
      "Needs correction:  cat   (heard: that)\n",
      "Correct:  is   (heard: is)\n",
      "Needs correction:  sleeping   (heard: slip)\n",
      "\n",
      "Audio help for tricky words:\n",
      "Audio explanation: We say 'the'. The 'th' sound. The letters T and H together make the sound 'th'. Put your tongue gently between your teeth and blow air: th. For example: the, this, that.\n",
      "Audio explanation: We say 'cat'. The short 'a' sound. Short 'a' is a quick sound: 'a', like in 'cat', 'hat', 'bat'. For example: cat, hat, bat.\n",
      "Audio explanation: We say 'sleeping'. The long 'ee' sound. The letters E E together make a long E sound: 'ee', like in 'sleep', 'feet', 'keep'. For example: sleep, feet, keep.\n",
      "\n",
      "Overall: Needs practice with this sentence.\n",
      "============================================================\n",
      "Sentence s02\n",
      "Target:    The dog is very happy.\n",
      "Predicted: sa dok reddy happy\n",
      "WER: 0.80 -> Score: 0.20\n",
      "\n",
      "Word-level feedback:\n",
      "Needs correction:  the   (heard: sa)\n",
      "Needs correction:  dog   (heard: sa)\n",
      "Needs correction:  is   (heard: sa)\n",
      "Needs correction:  very   (heard: sa)\n",
      "Correct:  happy   (heard: happy)\n",
      "\n",
      "Audio help for tricky words:\n",
      "Audio explanation: We say 'the'. The 'th' sound. The letters T and H together make the sound 'th'. Put your tongue gently between your teeth and blow air: th. For example: the, this, that.\n",
      "Audio explanation: We say 'dog', not 'sa'. Let's repeat 'dog' together.\n",
      "Audio explanation: We say 'is', not 'sa'. Let's repeat 'is' together.\n",
      "Audio explanation: We say 'very', not 'sa'. Let's repeat 'very' together.\n",
      "\n",
      "Overall: Needs practice with this sentence.\n",
      "============================================================\n",
      "Sentence s03\n",
      "Target:    The sun is shining.\n",
      "Predicted: zasan es shine\n",
      "WER: 1.00 -> Score: 0.00\n",
      "\n",
      "Word-level feedback:\n",
      "Needs correction:  the   (heard: zasan)\n",
      "Needs correction:  sun   (heard: zasan)\n",
      "Needs correction:  is   (heard: zasan)\n",
      "Needs correction:  shining   (heard: zasan)\n",
      "\n",
      "Audio help for tricky words:\n",
      "Audio explanation: We say 'the'. The 'th' sound. The letters T and H together make the sound 'th'. Put your tongue gently between your teeth and blow air: th. For example: the, this, that.\n",
      "Audio explanation: We say 'sun', not 'zasan'. Let's repeat 'sun' together.\n",
      "Audio explanation: We say 'is', not 'zasan'. Let's repeat 'is' together.\n",
      "Audio explanation: We say 'shining', not 'zasan'. Let's repeat 'shining' together.\n",
      "\n",
      "Overall: Needs practice with this sentence.\n",
      "============================================================\n",
      "Sentence s04\n",
      "Target:    She has a red ball.\n",
      "Predicted: she had and red all\n",
      "WER: 0.60 -> Score: 0.40\n",
      "\n",
      "Word-level feedback:\n",
      "Correct:  she   (heard: she)\n",
      "Needs correction:  has   (heard: had)\n",
      "Needs correction:  a   (heard: had)\n",
      "Correct:  red   (heard: red)\n",
      "Needs correction:  ball   (heard: all)\n",
      "\n",
      "Audio help for tricky words:\n",
      "Audio explanation: We say 'has', not 'had'. Let's repeat 'has' together.\n",
      "Audio explanation: We say 'a', not 'had'. Let's repeat 'a' together.\n",
      "Audio explanation: We say 'ball', not 'all'. Let's repeat 'ball' together.\n",
      "\n",
      "Overall: Needs practice with this sentence.\n",
      "============================================================\n",
      "Sentence s05\n",
      "Target:    The bird is on the tree.\n",
      "Predicted: the bart es on zat tiri\n",
      "WER: 0.67 -> Score: 0.33\n",
      "\n",
      "Word-level feedback:\n",
      "Correct:  the   (heard: the)\n",
      "Needs correction:  bird   (heard: bart)\n",
      "Needs correction:  is   (heard: bart)\n",
      "Correct:  on   (heard: on)\n",
      "Needs correction:  the   (heard: zat)\n",
      "Needs correction:  tree   (heard: zat)\n",
      "\n",
      "Audio help for tricky words:\n",
      "Audio explanation: We say 'bird', not 'bart'. Let's repeat 'bird' together.\n",
      "Audio explanation: We say 'is', not 'bart'. Let's repeat 'is' together.\n",
      "Audio explanation: We say 'the'. The 'th' sound. The letters T and H together make the sound 'th'. Put your tongue gently between your teeth and blow air: th. For example: the, this, that.\n",
      "Audio explanation: We say 'tree'. The long 'ee' sound. The letters E E together make a long E sound: 'ee', like in 'sleep', 'feet', 'keep'. For example: sleep, feet, keep.\n",
      "\n",
      "Overall: Needs practice with this sentence.\n",
      "============================================================\n",
      "Sentence s06\n",
      "Target:    The mouse is hiding under the table.\n",
      "Predicted: the mouse is hyde ander the table\n",
      "WER: 0.29 -> Score: 0.71\n",
      "\n",
      "Word-level feedback:\n",
      "Correct:  the   (heard: the)\n",
      "Correct:  mouse   (heard: mouse)\n",
      "Correct:  is   (heard: is)\n",
      "Needs correction:  hiding   (heard: hyde)\n",
      "Needs correction:  under   (heard: hyde)\n",
      "Correct:  the   (heard: the)\n",
      "Correct:  table   (heard: table)\n",
      "\n",
      "Audio help for tricky words:\n",
      "Audio explanation: We say 'hiding', not 'hyde'. Let's repeat 'hiding' together.\n",
      "Audio explanation: We say 'under', not 'hyde'. Let's repeat 'under' together.\n",
      "\n",
      "Overall: Good, but some words need practice.\n",
      "============================================================\n",
      "Sentence s07\n",
      "Target:    Please take the blue book.\n",
      "Predicted: place teg the boloe wok\n",
      "WER: 0.80 -> Score: 0.20\n",
      "\n",
      "Word-level feedback:\n",
      "Needs correction:  please   (heard: place)\n",
      "Needs correction:  take   (heard: place)\n",
      "Correct:  the   (heard: the)\n",
      "Needs correction:  blue   (heard: boloe)\n",
      "Needs correction:  book   (heard: boloe)\n",
      "\n",
      "Audio help for tricky words:\n",
      "Audio explanation: We say 'please', not 'place'. Let's repeat 'please' together.\n",
      "Audio explanation: We say 'take', not 'place'. Let's repeat 'take' together.\n",
      "Audio explanation: We say 'blue'. The magic 'e'. When a word ends with a silent 'e', the vowel often says its name. For example, 'cap' becomes 'cape'. For example: make, ride, bike.\n",
      "Audio explanation: We say 'book', not 'boloe'. Let's repeat 'book' together.\n",
      "\n",
      "Overall: Needs practice with this sentence.\n",
      "============================================================\n",
      "Sentence s08\n",
      "Target:    The fox runs fast.\n",
      "Predicted: the fox aran fast\n",
      "WER: 0.25 -> Score: 0.75\n",
      "\n",
      "Word-level feedback:\n",
      "Correct:  the   (heard: the)\n",
      "Correct:  fox   (heard: fox)\n",
      "Needs correction:  runs   (heard: aran)\n",
      "Correct:  fast   (heard: fast)\n",
      "\n",
      "Audio help for tricky words:\n",
      "Audio explanation: We say 'runs', not 'aran'. Let's repeat 'runs' together.\n",
      "\n",
      "Overall: Good, but some words need practice.\n",
      "============================================================\n",
      "Sentence s09\n",
      "Target:    The cake is on the plate.\n",
      "Predicted: the cake on without flight\n",
      "WER: 0.50 -> Score: 0.50\n",
      "\n",
      "Word-level feedback:\n",
      "Correct:  the   (heard: the)\n",
      "Correct:  cake   (heard: cake)\n",
      "Needs correction:  is   (heard: None)\n",
      "Correct:  on   (heard: on)\n",
      "Needs correction:  the   (heard: without)\n",
      "Needs correction:  plate   (heard: without)\n",
      "\n",
      "Audio help for tricky words:\n",
      "Audio explanation: Let's try the word 'is' again. Read it slowly and clearly.\n",
      "Audio explanation: We say 'the'. The 'th' sound. The letters T and H together make the sound 'th'. Put your tongue gently between your teeth and blow air: th. For example: the, this, that.\n",
      "Audio explanation: We say 'plate', not 'without'. Let's repeat 'plate' together.\n",
      "\n",
      "Overall: Needs practice with this sentence.\n",
      "============================================================\n",
      "Sentence s10\n",
      "Target:    The little sheep is near the fence.\n",
      "Predicted: the little sheep es they ar the fance\n",
      "WER: 0.57 -> Score: 0.43\n",
      "\n",
      "Word-level feedback:\n",
      "Correct:  the   (heard: the)\n",
      "Correct:  little   (heard: little)\n",
      "Correct:  sheep   (heard: sheep)\n",
      "Needs correction:  is   (heard: es)\n",
      "Needs correction:  near   (heard: es)\n",
      "Correct:  the   (heard: the)\n",
      "Needs correction:  fence   (heard: fance)\n",
      "\n",
      "Audio help for tricky words:\n",
      "Audio explanation: We say 'is', not 'es'. Let's repeat 'is' together.\n",
      "Audio explanation: We say 'near', not 'es'. Let's repeat 'near' together.\n",
      "Audio explanation: We say 'fence', not 'fance'. Let's repeat 'fence' together.\n",
      "\n",
      "Overall: Needs practice with this sentence.\n",
      "Average WER: 0.6223809523809524\n",
      "Average Score: 0.37761904761904763\n",
      "Best Sentence: {'id': 's08', 'score': 0.75}\n",
      "Worst Sentence: {'id': 's03', 'score': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all sentences where audio is available\n",
    "all_results = []\n",
    "\n",
    "for _, row in sentences_df.iterrows():\n",
    "    res = evaluate_sentence(row, child_suffix=\"child\")\n",
    "    if res is not None:\n",
    "        all_results.append(res)\n",
    "\n",
    "summary_df = pd.DataFrame([\n",
    "    {\n",
    "        \"id\": r[\"id\"],\n",
    "        \"wer\": r[\"wer\"],\n",
    "        \"score\": r[\"score\"],\n",
    "        \"target\": r[\"target\"],\n",
    "        \"predicted\": r[\"predicted\"]\n",
    "    }\n",
    "    for r in all_results\n",
    "])\n",
    "summary_df\n",
    "print(\"Average WER:\", summary_df[\"wer\"].mean())\n",
    "print(\"Average Score:\", summary_df[\"score\"].mean())\n",
    "print(\"Best Sentence:\", summary_df.loc[summary_df[\"score\"].idxmax(), [\"id\", \"score\"]].to_dict())\n",
    "print(\"Worst Sentence:\", summary_df.loc[summary_df[\"score\"].idxmin(), [\"id\", \"score\"]].to_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbaf8a4-93ab-4f70-98bb-8c12ca8671d2",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "The Wav2Vec2 model performs reasonably well on short, clearly articulated sentences \n",
    "(e.g., s06 and s08), but struggles with longer or more complex recordings (e.g., s01 - s03, s07).  \n",
    "The most common error patterns include:\n",
    "\n",
    "- **Substitution of “th” → “t”/“s”** (e.g., “the” → “that”, “sa”), a known challenge in child speech.\n",
    "- **Vowel confusion** in words like “cat”, “ball”, “sun”.\n",
    "- **Dropping or simplifying endings**, such as \"-ing\" → \"in\" or \"slip\".\n",
    "- **Catastrophic decoding errors** where multiple words collapse into one output (e.g., “zasan”).\n",
    "\n",
    "These results match findings in speech research that adult-trained ASR models \n",
    "have difficulty with children’s higher pitch, shorter phoneme duration, and inconsistent articulation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7292bb-99c6-465d-b953-df7dbaef6db9",
   "metadata": {},
   "source": [
    "## Interpretation of Results\n",
    "\n",
    "The average WER across the 10 sentences was approximately **0.62**, meaning that\n",
    "the model misrecognized about 62% of the words in the recordings. This confirms\n",
    "findings in speech recognition research that adult-trained ASR models perform\n",
    "poorly on children’s speech due to differences in pitch, articulation, speech\n",
    "rate, and phoneme duration.\n",
    "\n",
    "The model performed best on shorter, clearly articulated sentences such as:\n",
    "\n",
    "- *“The fox runs fast.”* (WER = 0.25)\n",
    "- *“The mouse is hiding under the table.”* (WER = 0.29)\n",
    "\n",
    "It performed worst on more difficult sentences, especially those beginning with\n",
    "\"the\", which the model frequently misrecognized as “that”, “sa”, or “zasan”.\n",
    "The sentence *“The sun is shining.”* was not recognized correctly at all\n",
    "(WER = 1.00), demonstrating the model's difficulty with child pronunciation of\n",
    "initial consonant clusters and long vowel sounds.\n",
    "\n",
    "Despite limited transcription accuracy, the system successfully:\n",
    "1. Detected incorrect words,\n",
    "2. Mapped errors to simple phonics rules (e.g., “th”, “short a”, “long ee”),\n",
    "3. Generated accessible spoken feedback for the child.\n",
    "\n",
    "This shows that combining a pretrained ASR model with rule-based phonics \n",
    "explanations can provide meaningful instructional feedback, even when the \n",
    "transcriptions are imperfect.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9166fdbb-e3d2-49c3-97c2-0dc44dfa40e2",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This project demonstrates that a pretrained Wav2Vec2 speech model can be used to provide \n",
    "automatic reading feedback for children. Although transcription accuracy on child speech \n",
    "is limited (average WER ≈ 0.62), the combination of ASR output with word alignment and a phonics\n",
    "rule engine, the prototype successfully identifies difficult words and provides\n",
    "child-friendly spoken explanations. This hybrid approach shows promise for\n",
    "building supportive early-literacy tools.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kidread)",
   "language": "python",
   "name": "kidread"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
